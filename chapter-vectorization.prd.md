### 1. 产品需求文档 (PRD)

**1.1. 背景**
用户在处理长篇文档（如小说、技术手册、法律文件）时，常常需要基于章节进行语义搜索。当前的向量化流程将整个文档视为一个整体，切分成的文本块（chunks）缺乏章节归属信息，导致无法在特定章节内进行精确的问答或信息检索。

**1.2. 目标**
引入“按章节向量化”功能，允许用户通过正则表达式定义章节标题的模式。系统将根据匹配到的章节对文本进行预分割，并在生成的向量数据中添加章节元数据。这将优化长文档的检索体验，提高上下文相关性。

**1.3. 用户故事**
- 作为一名学者，我希望能对一本在线古籍的特定章节进行提问，以快速定位相关论述。
- 作为一名技术人员，我希望能在一个复杂的API文档中，只搜索“网络请求”章节的内容，以过滤无关信息。
- 作为一名小说爱好者，我想搜索某个特定角色的出场章节，并分析其在不同章节中的行为变化。

**1.4. 功能需求**
1.  **UI交互**
    - 在“内容选择” -> “文件”区域下，增加一个“章节分割正则表达式”的文本输入框。
    - 输入框旁应有明确的提示文字，说明其用途（例如：“用于识别章节标题的正则表达式，留空则不按章节分割”）。
    - 提供一个默认的正则表达式示例，帮助用户理解格式，例如 `^第[一二三四五六七八九十百千万\d]+章.*`。
2.  **核心逻辑**
    - 用户上传文件后，系统检查是否提供了“章节分割正则表达式”。
    - 如果提供了正则表达式：
        - 系统使用该表达式对文件内容进行扫描，识别所有匹配的章节标题。
        - 将原文案按照章节边界进行切割，形成多个大块文本。
        - 对每个章节内的文本，再按照现有的`chunkSize`和`overlap`逻辑进行细粒度切分。
        - 每个最终的文本块（chunk）在存入向量数据库时，其元数据（metadata）必须包含以下字段：
            - `chapter`: 匹配到的章节标题全文。
            - `sequence_id`: 该文本块在整个文档中的顺序编号（从0开始）。
    - 如果未提供正则表达式或表达式无效/未匹配到任何内容：
        - 系统回退到现有逻辑，将整个文档作为一个整体进行切分。
        - 生成的文本块元数据中**仅**包含 `sequence_id`，不包含 `chapter` 字段。
3.  **数据处理**
    - 向量化后的数据能被现有的查询系统正确解析和使用。
    - 查询时，可以利用`chapter`元数据进行过滤，但这部分功能的实现不在本次迭代范围内，本次仅确保元数据被正确存储。

**1.5. 非功能性需求**
- **性能**: 增加章节分割步骤对整体向量化时长的影响应控制在10%以内。
- **健壮性**: 无效的正则表达式不应导致程序崩溃，应有错误处理机制并回退到默认行为。
- **易用性**: UI提示应清晰易懂，降低用户使用门槛。

**1.6. 验收标准**
1.  UI上成功添加了正则表达式输入框和提示。
2.  在设置中输入有效的正则表达式并上传包含匹配章节的文档，向量化后检查数据库，确认每个chunk的元数据都包含正确的`chapter`和`sequence_id`。
3.  不输入正则表达式或输入无效表达式，向量化后检查数据库，确认每个chunk的元数据只包含`sequence_id`。
4.  上传不包含任何匹配章节的文档，即使提供了正则表达式，其行为也应同标准3。
